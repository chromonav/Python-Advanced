{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multithreading and Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Threading\n",
    "* typically, concurrency is created so that we can do some task while I/O is happening (e.g., a server can start processing a new request while waiting for data from a previous request to arrive)\n",
    "* we can create objects that appear to be running independently, but simultaneously\n",
    "* the job of threading is to enable an application to be responsive\n",
    "* CPython, the default implementation of Python, has a Global Interpreter Lock (GIL), which prevents your application from doing two things at once, but rather, the CPU time is being rationed across your threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simple threading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated squares up to 7,327,480 * 7,327,480 = 53,691,948,495,441\n",
      "while you typed \"hello\"\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class InputReader(Thread):\n",
    "    \"\"\"Thread example, extends Thread class\"\"\"\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Whatever is in the run method (or called from\n",
    "        it) is executed in a separate thread\n",
    "        \"\"\"\n",
    "        self.line_of_text = input('Enter some text: ')\n",
    "\n",
    "input('Are you ready? When you hit return the thread will start.')\n",
    "thread = InputReader() # create thread object\n",
    "thread.start() # cf. thread.run() for no concurrency\n",
    "\n",
    "count, result = 1, 1\n",
    "\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "\n",
    "print(f'calculated squares up to {count:,} * {count:,} = {result:,}')\n",
    "print(f'while you typed \"{thread.line_of_text}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is 58°F in Boulder\n",
      "it is 68°F in Atlanta\n",
      "it is 61°F in San%20Francisco\n",
      "it is 48°F in Reno\n",
      "it is 77°F in Honolulu\n",
      "it is 57°F in Zurich\n",
      "it is 104°F in Dubai\n",
      "it is 60°F in Dublin\n",
      "it is 79°F in Hyderabad\n",
      "it is 65°F in Rome\n",
      "Got 10 temps in 0.24003291130065918 seconds\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "\n",
    "cities = ['Boulder', 'Atlanta', 'San%20Francisco',\n",
    "          'Reno', 'Honolulu', 'Zurich', 'Dubai',\n",
    "          'Dublin', 'Hyderabad', 'Rome']\n",
    "\n",
    "class TempGetter(Thread):\n",
    "    def __init__(self, city):\n",
    "        \"\"\"Initialize our thread\n",
    "\n",
    "In the previous example, our class which extended\n",
    "Thread did not need an __init__ method, because\n",
    "there was no per-thread information to store. Which\n",
    "means that the __init__ method from the superclass\n",
    "(Thread) was called automatically. Here, because we\n",
    "need to store per-thread information (the city), we\n",
    "have to explicitly call the__init__ method of Thread.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.city = city\n",
    "\n",
    "    def run(self):\n",
    "        url_template = (\n",
    "            'http://api.openweathermap.org/data/2.5/' \n",
    "            'weather?q={}&units=imperial'\n",
    "                        '&&APPID=10d4440bbaa8581bb8da9bd1fbea5617')\n",
    "        response = urlopen(url_template.format(self.city))\n",
    "        data = json.loads(response.read().decode())\n",
    "        self.temperature = data['main']['temp']\n",
    "        \n",
    "threads = [TempGetter(city) for city in cities] # creates 10 threads\n",
    "start = time.time()\n",
    "\n",
    "# start all 10 threads\n",
    "for thread in threads:\n",
    "    thread.start() # not run()\n",
    "\n",
    "# wait for all 10 threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "for thread in threads:\n",
    "    print(f\"it is {thread.temperature:.0f}°F in {thread.city}\")\n",
    "print(f\"Got {len(threads)} temps in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Threading (cont'd)\n",
    "* the main problem with threads is also their primary advantage–shared memory\n",
    " * all threads have access to all the memory\n",
    " * what if two threads access the same data?\n",
    "* synchronization is the solution, but it's tricky\n",
    " * bugs due to incorrect synchronization can be very difficult to find due to ordering issues\n",
    "* one solution is to force communication between threads to occur using a data structure that has built in locking, such as queue.Queue\n",
    "* disadvantages could be outweighed by the fact that shared memory is FAST, except for the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat A Task Every So Often...\n",
    "* ...using a Timer (subclass of thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplied up to 0\n",
      "multiplied up to 10000000\n",
      "multiplied up to 20000000\n",
      "multiplied up to 30000000\n",
      "multiplied up to 40000000\n",
      "multiplied up to 50000000\n",
      "multiplied up to 60000000\n",
      "Do the thing you want to every so often\n",
      "multiplied up to 70000000\n",
      "multiplied up to 80000000\n",
      "multiplied up to 90000000\n"
     ]
    }
   ],
   "source": [
    "from threading import Timer, Event\n",
    " \n",
    "def every_so_often():\n",
    "    if not done.is_set():\n",
    "        print('Do the thing you want to every so often')\n",
    "        Timer(5.0, every_so_often).start()\n",
    " \n",
    "done = Event()\n",
    "Timer(5.0, every_so_often).start()\n",
    " \n",
    "for count in range(100000000):\n",
    "    prod = count * count\n",
    "    if count % 10_000_000 == 0:\n",
    "        print('multiplied up to', count)\n",
    " \n",
    "done.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lab: threads\n",
    "* create a program which uses threads to simulate a database server\n",
    "* your \"database server\" should simply be a thread which sleeps for a random interval (check out __`time.sleep()`__ and __`random.randint()`__ if you're not familiar with them)\n",
    "* your main thread should get input from the user and respond to it (perhaps reversing the input given by the user) while the database thread is busy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Queue in module queue:\n",
      "\n",
      "class Queue(builtins.object)\n",
      " |  Queue(maxsize=0)\n",
      " |  \n",
      " |  Create a queue object with a given maximum size.\n",
      " |  \n",
      " |  If maxsize is <= 0, the queue size is infinite.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, maxsize=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  empty(self)\n",
      " |      Return True if the queue is empty, False otherwise (not reliable!).\n",
      " |      \n",
      " |      This method is likely to be removed at some point.  Use qsize() == 0\n",
      " |      as a direct substitute, but be aware that either approach risks a race\n",
      " |      condition where a queue can grow before the result of empty() or\n",
      " |      qsize() can be used.\n",
      " |      \n",
      " |      To create code that needs to wait for all queued tasks to be\n",
      " |      completed, the preferred technique is to use the join() method.\n",
      " |  \n",
      " |  full(self)\n",
      " |      Return True if the queue is full, False otherwise (not reliable!).\n",
      " |      \n",
      " |      This method is likely to be removed at some point.  Use qsize() >= n\n",
      " |      as a direct substitute, but be aware that either approach risks a race\n",
      " |      condition where a queue can shrink before the result of full() or\n",
      " |      qsize() can be used.\n",
      " |  \n",
      " |  get(self, block=True, timeout=None)\n",
      " |      Remove and return an item from the queue.\n",
      " |      \n",
      " |      If optional args 'block' is true and 'timeout' is None (the default),\n",
      " |      block if necessary until an item is available. If 'timeout' is\n",
      " |      a non-negative number, it blocks at most 'timeout' seconds and raises\n",
      " |      the Empty exception if no item was available within that time.\n",
      " |      Otherwise ('block' is false), return an item if one is immediately\n",
      " |      available, else raise the Empty exception ('timeout' is ignored\n",
      " |      in that case).\n",
      " |  \n",
      " |  get_nowait(self)\n",
      " |      Remove and return an item from the queue without blocking.\n",
      " |      \n",
      " |      Only get an item if one is immediately available. Otherwise\n",
      " |      raise the Empty exception.\n",
      " |  \n",
      " |  join(self)\n",
      " |      Blocks until all items in the Queue have been gotten and processed.\n",
      " |      \n",
      " |      The count of unfinished tasks goes up whenever an item is added to the\n",
      " |      queue. The count goes down whenever a consumer thread calls task_done()\n",
      " |      to indicate the item was retrieved and all work on it is complete.\n",
      " |      \n",
      " |      When the count of unfinished tasks drops to zero, join() unblocks.\n",
      " |  \n",
      " |  put(self, item, block=True, timeout=None)\n",
      " |      Put an item into the queue.\n",
      " |      \n",
      " |      If optional args 'block' is true and 'timeout' is None (the default),\n",
      " |      block if necessary until a free slot is available. If 'timeout' is\n",
      " |      a non-negative number, it blocks at most 'timeout' seconds and raises\n",
      " |      the Full exception if no free slot was available within that time.\n",
      " |      Otherwise ('block' is false), put an item on the queue if a free slot\n",
      " |      is immediately available, else raise the Full exception ('timeout'\n",
      " |      is ignored in that case).\n",
      " |  \n",
      " |  put_nowait(self, item)\n",
      " |      Put an item into the queue without blocking.\n",
      " |      \n",
      " |      Only enqueue the item if a free slot is immediately available.\n",
      " |      Otherwise raise the Full exception.\n",
      " |  \n",
      " |  qsize(self)\n",
      " |      Return the approximate size of the queue (not reliable!).\n",
      " |  \n",
      " |  task_done(self)\n",
      " |      Indicate that a formerly enqueued task is complete.\n",
      " |      \n",
      " |      Used by Queue consumer threads.  For each get() used to fetch a task,\n",
      " |      a subsequent call to task_done() tells the queue that the processing\n",
      " |      on the task is complete.\n",
      " |      \n",
      " |      If a join() is currently blocking, it will resume when all items\n",
      " |      have been processed (meaning that a task_done() call was received\n",
      " |      for every item that had been put() into the queue).\n",
      " |      \n",
      " |      Raises a ValueError if called more times than there were items\n",
      " |      placed in the queue.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "help(queue.Queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: []\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 12 instead\n",
      "WARNING: server unable to handle request 12...requeuing\n",
      "Queue: [12]\n",
      "Database server handling request for 12 seconds\n",
      "Enqueueing: 3\n",
      "Enqueueing: 3\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 12 instead\n",
      "Enqueueing: h\n",
      "Invalid integer (h), adding 13 instead\n",
      "Database server successfully handled request\n",
      "Queue: [3, 3, 12, 13]\n",
      "Database server handling request for 3 seconds\n",
      "Enqueueing: 4\n",
      "Enqueueing: 67\n",
      "Database server successfully handled request\n",
      "Queue: [3, 12, 13, 4, 67]\n",
      "Database server handling request for 3 seconds\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 15 instead\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 12 instead\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 15 instead\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 15 instead\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 15 instead\n",
      "Enqueueing: \n",
      "Invalid integer (), adding 10 instead\n"
     ]
    }
   ],
   "source": [
    "%run dbserver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiprocessing\n",
    "* the Python multiprocessing library is designed for cases where CPU-bound jobs needs to happen in parallel and multiple cores are available\n",
    "* advantages\n",
    " * separate memory space for each process\n",
    " * code is usually straightforward compared to threads\n",
    " * avoids GIL limitation\n",
    " * eliminates synchronization (assuming no shared memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Simple Multiprocessing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "class MuchCPU(Process):\n",
    "    def run(self):\n",
    "        print(os.getpid()) # get process ID\n",
    "        for i in range(80_000_000):\n",
    "            result = i * i\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    print('Running...')\n",
    "    procs = [MuchCPU() for f in range(cpu_count())]\n",
    "    t = time.time()\n",
    "\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "    \n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    \n",
    "    print('work took {} seconds'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing (cont'd)\n",
    "* no reason for more processes than there are processors\n",
    " * only `cpu_count()` procs can run simultaneously\n",
    " * each proc consumes resources with a full copy of Python interpreter\n",
    " * interproc communication is expensive\n",
    " * creating procs takes a nonzero amount of time\n",
    "* so we create at most `cpu_count()` processes when the program starts and have them execute tasks as needed\n",
    "* easy to implement a basic series of communicating processes to do this, but it can be tricky to debug, test, and get correct–we don't have to do all this work because the Python developers have already done it for us–multiprocessing pools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing Pools\n",
    "* pools abstract away the overhead of figuring out what code is running in main process and what code is running in subprocess\n",
    "* abstraction restricts the number of places that code in different processes interact with each other, making it easier to keep track of\n",
    "* pools also hide the passing of data between processes\n",
    " * using a pool looks much like a function call–you pass data into a function, it's executed in another process or processes, and when the work is complete, a value is returned\n",
    " * under the hood, a lot of work is being done to support this–objects in one process are being pickled (serialized) and passed into a pipe, then another process retrieves data from the pipe and unpickles it. Work is done in the subprocess and a result is produced. The result is pickled and passed into a pipe. Eventually, the original process unpickles it and returns it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiprocessing Pool Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def prime_factor(value, level=0):\n",
    "    factors = []\n",
    "    if level:\n",
    "        print('    ' * level, 'prime_factor(', value, ', ', level, ') ', os.getpid(), sep='')\n",
    "    for divisor in range(2, value - 1):\n",
    "        quotient, remainder = divmod(value, divisor)\n",
    "        if not remainder:\n",
    "            factors.extend(prime_factor(divisor, level + 1))\n",
    "            factors.extend(prime_factor(quotient, level + 1))\n",
    "            break\n",
    "    else:\n",
    "        factors = [value]\n",
    "    return factors\n",
    "\n",
    "if __name__ == '__main__': # distiguishes between running and importing\n",
    "    pool = Pool()\n",
    "\n",
    "    to_factor = [\n",
    "        random.randint(40_000_000, 80_000_000) \n",
    "                for _ in range(64)\n",
    "    ]\n",
    "    print(to_factor)\n",
    "    results = pool.map(prime_factor, to_factor)\n",
    "    for value, factors in zip(to_factor, results):\n",
    "        print(\"The factors of {} are {}\".format(value, factors))\n",
    "    #print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lab: Multiprocessing Pool\n",
    "* write a program to compute 1!…48! using a multiprocessing pool\n",
    "* won't be much of a parallelism example, but it's easy to code\n",
    "* use previous example as a template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multithreading/Multiprocessing for Python 3\n",
    "* Python 3.2 introduced the __`concurrent.futures`__ module for multithreading  via the ThreadPoolExecutor, or multiprocessing, using ProcessPoolExecutor\n",
    "* it's been backported to Python 2.6+ and can be installed using __`pip install futures`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "URLS = ['http://www.japan.go.jp/',\n",
    "        'http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://www.python.org',\n",
    "        'http://www.wikipedia.org',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://www.apple.com',\n",
    "        'http://blahblahblah.org']\n",
    "\n",
    "# Retrieve a single page and report the URL and contents\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        return conn.read()\n",
    "\n",
    "start = time.time()\n",
    "# We use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # start the load operations and mark each future with its URL\n",
    "    future_to_url = {\n",
    "        executor.submit(load_url, url, 60): url for url in URLS }\n",
    "    \n",
    "    # asynchronously wait for threads to complete...\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f'{url} generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'{url} is {len(data)} bytes')\n",
    "            \n",
    "print(f'Completed in {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial():\n",
    "    start = time.time()\n",
    "    for url in URLS:\n",
    "        try:\n",
    "            data = load_url(url, 60)\n",
    "        except Exception as exc:\n",
    "            print(f'{url} generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'{url} is {len(data)} bytes')\n",
    "            \n",
    "    print(f'Completed in {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    " \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    " \n",
    "def downloader(url):\n",
    "    \"\"\"\n",
    "    Downloads the specified URL and saves it to disk\n",
    "    \"\"\"\n",
    "    req = urllib.request.urlopen(url)\n",
    "    filename = os.path.basename(url)\n",
    "    ext = os.path.splitext(url)[1]\n",
    "    if not ext:\n",
    "        raise RuntimeError('URL does not contain an extension')\n",
    " \n",
    "    with open(filename, 'wb') as file_handle:\n",
    "        while True:\n",
    "            chunk = req.read(1024)\n",
    "            if not chunk:\n",
    "                break\n",
    "            file_handle.write(chunk)\n",
    "    msg = 'Finished downloading {filename}'.format(filename=filename)\n",
    "    return msg\n",
    " \n",
    "def main(urls):\n",
    "    \"\"\"\n",
    "    Create a thread pool and download specified urls\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(downloader, url) for url in urls]\n",
    "        for future in as_completed(futures):\n",
    "            print('sik', future.result())\n",
    "\n",
    "urls = [\"https://www.irs.gov/pub/irs-pdf/f1040.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040a.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040ez.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040es.pdf\",\n",
    "        \"https://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"]\n",
    "main(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "\n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    \n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print(f'{number} is prime: {prime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial():\n",
    "    for prime in PRIMES:\n",
    "        print(f'{prime} is prime: {is_prime(prime)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
